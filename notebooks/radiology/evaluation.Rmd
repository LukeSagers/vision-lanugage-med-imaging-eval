---
title: "evaluation_and_comparison.R"
author: "Aashna Shah"
date: "2024-03-13"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(caret)
```

```{r}
base_dir <- "/Users/aashnashah/Dropbox/Research/derm-gemini-vs-gpt4/"
data_dir <- "data/radiology/"
tables_dir <- "tables/radiology/"

prompt_df <- read.csv(paste0(base_dir, data_dir, "prompts.csv"))
```


```{r cars}
# Read in Gemini results and add model column
gemini_results <- read.csv(paste0(base_dir, data_dir, "apiResults/gemini_chexpert_results_20240312.csv"))
gemini_results$model <- "Gemini Pro Vision"

# Read in GPT-4v results and add model column
openai_results <- read.csv(paste0(base_dir, data_dir, "apiResults/gpt4v_chexpert_results_20240318.csv"))
openai_results$model <- "GPT-4v with Vision"

api_results <- rbind(openai_results, gemini_results)

# Read in demographics data
demographics <- read.csv(paste0(base_dir, data_dir, "CheXpert/processed_test_set_2024-03-10.csv"))
demographics <- read.csv(paste0(base_dir, data_dir, "CheXpert/processed_test_val_set_20240319.csv"))
demographics$AGE_GROUP <- cut(demographics$AGE_AT_CXR, 
breaks = c(0, 44, 70, Inf), labels = c("18-44", "44-70", "70-96"))

# Merge GPT-4v results with demographics
df <- merge(api_results, demographics, by.x = "Filename", by.y = "Path", all.x = TRUE)

df <- df[order(df$Filename, df$PromptID), ]

# Displaying the head of the combined dataframe
head(df)
```

```{r}
print(nrow(demographics))
print(nrow(df))
```

```{r}
df
```

```{r pressure, echo=FALSE}

# Define a function to categorize the model"s response
categorize_response <- function(response) {
  response <- tolower(response)
    ifelse(grepl("\\b(error)\\b", response), "Blocked",
        ifelse(grepl("sorry|cannot|not possible|impossible to", response, ignore.case = TRUE), "Refused",
           ifelse(grepl("\\b(normal)\\b", response) | grepl("\\b(abnormal)\\b", response), "Diagnosed",
              ifelse(is.na(response), "Blocked", "Blocked")
                )
         )
  )
}

# Define a function to extract the initial response
extract_initial_response <- function(response) {
  response <- tolower(response)
  ifelse(grepl("\\b(abnormal)\\b", response), 1,
         ifelse(grepl("\\b(normal)\\b", response), 0, NA)
  )
}

# Function to calculate unique values
calculate_unique_values <- function(data_frame, column_name) {
  unique_values <- unique(data_frame[[column_name]])
  return(unique_values)
}

# Clean the dataframe
df_cleaned <- df %>%
  mutate(CategorizedResponse = categorize_response(Response),
         PredictedDiagnosis = extract_initial_response(Response))


# Calculate unique values for cleaned Response column
unique_values <- calculate_unique_values(df_cleaned, 'Response')
print(unique_values)

unique_values <- calculate_unique_values(df_cleaned, 'CategorizedResponse')
print(unique_values)

unique_values <- calculate_unique_values(df_cleaned, 'PredictedDiagnosis')
print(unique_values)

df_cleaned <- df_cleaned %>%
  #select(model, Filename, PromptID, GENDER, AGE_AT_CXR, AGE_GROUP, PRIMARY_RACE, Ethnicity, Race, No.Finding, CategorizedResponse, Response, PredictedDiagnosis, abnormal) %>% 
  filter(PromptID < 8) %>% 
  mutate(PromptID = PromptID + 1)

df_cleaned
```


```{r}
result <- df_cleaned %>%
  mutate(PromptID_ = paste0("P", as.numeric(PromptID)))

# Merge with prompt_df based on PromptID_
result_with_prompt <- merge(result, prompt_df, by.x = "PromptID_", by.y = "ID")

# Reorder columns with Full_Prompt as the first column
result_filtered_sorted <- result_with_prompt %>%
  select(Prompt, everything())
# Calculate counts of each CategorizedResponse for each model and PromptID

df_counts <- result_filtered_sorted %>%
  group_by(model, PromptID, CategorizedResponse) %>%
  summarize(Count = n())
```

```{r}
# Define the variable name dynamically

library(tidyverse)

generate_contingency_plot <- function(variable_name) {
  # Filter the data and calculate proportions
  contingency_table <- df_cleaned %>%
    group_by(PromptID, model, !!sym(variable_name), CategorizedResponse, .drop = FALSE) %>%
    summarise(
        Count = n(),
        .groups = "drop"
    ) %>%
    group_by(PromptID, model, !!sym(variable_name)) %>%
    mutate(Prop = round((Count / sum(Count)), 2)) %>%  # Round percentages to 2 decimal places
    filter(CategorizedResponse %in% c("Diagnosed", "Refused", "Blocked")) %>%
    pivot_wider(
        id_cols = c("model", "PromptID"),
        names_from = c(!!sym(variable_name), CategorizedResponse),
        values_from = Prop,
        values_fill = 0,
        names_sort = TRUE
    )
    
    contingency_table2 <- df_cleaned %>%
    group_by(PromptID, model, !!sym(variable_name), CategorizedResponse, .drop = FALSE) %>%
    summarise(
      Count = n(),
      .groups = "drop"
    ) %>%
    group_by(PromptID, model, !!sym(variable_name)) %>%
    mutate(Prop = Count / sum(Count)) %>%
    filter(CategorizedResponse %in% c("Diagnosed", "Refused", "Blocked")) 
  
  # Create the plot
  ggplot(contingency_table2, aes(x = factor(!!sym(variable_name)), y = Prop, fill = CategorizedResponse)) +
    geom_bar(stat = "identity", position = "stack") +
    scale_y_continuous(labels = scales::percent_format(scale = 1)) +  # Set y-axis labels as percentages
    facet_wrap(~PromptID + model, scales = "free_y") +  # Facet by both PromptID and model
    labs(x = "Variable Name", y = "Proportion", fill = "Response") +
    theme_minimal()

  return(list(contingency_table = contingency_table, plot = plot))
}

# List of variables to generate plots for
variables <- c('Race', 'AGE_GROUP', 'Support.Devices')

# Generate plots and contingency tables for each variable in the list
results <- lapply(variables, generate_contingency_plot)
for (i in seq_along(results)) {
  # View the contingency table
  results[[i]]$contingency_table <- results[[i]]$contingency_table %>%
    arrange(model)
  
  print(results[[i]]$contingency_table)
  
  # Save the contingency table as CSV
  csv_file <- paste0(base_dir, tables_dir, "xray_response_rate_", variables[i], ".csv")
  write.csv(results[[i]]$pivot_df, csv_file, row.names = FALSE)
  
  # View the plot
  print(results[[i]]$plot)
}

```
```{r}
# Define custom colors
custom_colors <- c(
  "Diagnosed" = "#1f77b4",   # blue
  "Refused" = "#ff7f0e",      # orange
  "Blocked" = "#2ca02c"       # green
)

# Plot the stacked bar plot
ggplot(df_counts, aes(x = factor(PromptID), y = Count, fill = CategorizedResponse)) +
  geom_bar(stat = "identity") +
  labs(
    title = "X-Rays",
    x = "Prompt ID",
    y = "Count",
    fill = "Response"
  ) +
  scale_fill_manual(values = custom_colors) +
  facet_wrap(~ model, scales = "free_x") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))


```

```{r}
# Use dcast to pivot the data frame
pivot_df <- df_counts %>% spread(key=CategorizedResponse, value = "Count") %>% select(Diagnosed, Refused, Blocked)

# Print the pivoted data frame
print(pivot_df)
write.csv(pivot_df, paste0(base_dir, tables_dir, "overall_response_rate.csv"), row.names = FALSE)

```

```{r}
calculate_metrics_with_CI <- function(data, n_bootstrap = 1000) {
  column_name <- "PredictedDiagnosis"
  
  if (!column_name %in% names(data)) {
    return(data.frame(Accuracy = NA, Sensitivity = NA, Specificity = NA, Precision = NA, Recall = NA, F1 = NA, `Balanced Accuracy` = NA))
  }
  
  calculate_single_sample <- function(prompt_value) {
    sample_data <- data %>%
      filter(PromptID == prompt_value) %>%
      drop_na({{ column_name }}, abnormal) %>%
      sample_frac(1, replace = TRUE)
    
    # Ensure that both TRUE and FALSE levels exist
    sample_data[[column_name]] <- factor(sample_data[[column_name]], levels = c(0, 1))
    sample_data$abnormal <- factor(sample_data$abnormal, levels = c(0, 1))
    
    cm <- confusionMatrix(as.factor(sample_data[[column_name]]), as.factor(sample_data$abnormal), positive = "1")
    
    return(data.frame(PromptID = prompt_value,
                      Size = nrow(sample_data),
                      Accuracy = cm$overall["Accuracy"], 
                      Sensitivity = cm$byClass["Sensitivity"], 
                      Specificity = cm$byClass["Specificity"], 
                      Precision = cm$byClass["Precision"], 
                      Recall = cm$byClass["Recall"], 
                      F1 = cm$byClass["F1"],
                      `Balanced Accuracy` = cm$byClass["Balanced Accuracy"]))
}
  
  prompts <- unique(data$PromptID)

  bootstrap_samples <- replicate(n_bootstrap, lapply(prompts, calculate_single_sample), simplify = FALSE) %>%
    bind_rows()
  
  metrics_with_CI <- bootstrap_samples %>%
    group_by(PromptID, Size) %>%
    summarise(across(everything(), list(mean = ~mean(., na.rm = TRUE), 
                                        lower = ~quantile(., 0.025, na.rm = TRUE), 
                                        upper = ~quantile(., 0.975, na.rm = TRUE))))
  
  return(metrics_with_CI)
}

```


```{r}
# Step 1: Filter by PromptID > 2 and PredictedDiagnosis is not NA
filtered_df <- df_cleaned %>%
  filter((model == "GPT-4v with Vision" & PromptID > 2 | model == "Gemini Pro Vision")  & !is.na(PredictedDiagnosis))

filenames_list <- filtered_df$Filename
filename_counts <- table(filenames_list)
filenames_at_least_12 <- names(filename_counts[filename_counts >= 14])
overlap_filtered_df <- df_cleaned %>%
  filter(Filename %in% filenames_at_least_12)

print(length(filenames_at_least_12))  
```

```{r}
master_df <- data.frame()
demographic_groups <- c("Overall", "AGE_GROUP", "Race")

df_results <- df_cleaned

for (group in demographic_groups) {
  
  if (group == "Overall") {
    metrics <- df_results %>%
        group_by(model) %>%
        do({
          metrics_result <- calculate_metrics_with_CI(.)
          as.data.frame(metrics_result)
        }) %>%
        ungroup()

    df <- data.frame(Category = rep("Overall", nrow(metrics)), Unique_Value = rep("Overall", nrow(metrics)), metrics)
    master_df <- rbind(master_df, df)
    
  } else {
    unique_values <- unique(df_results[[group]])
    
    for (value in unique_values) {
      sample_df <- df_results[df_results[[group]] == value, ]
      metrics <- sample_df %>%
        group_by(model) %>%
        do({
          metrics_result <- calculate_metrics_with_CI(.)
          as.data.frame(metrics_result)
        }) %>%
        ungroup()
      
      df <- data.frame(Category = rep(group, nrow(metrics)), Unique_Value = rep(value, nrow(metrics)), metrics)
      master_df <- rbind(master_df, df)
    }
  }
}

print(master_df)

# Calculate confidence intervals and format metrics
df <- master_df %>%
  mutate(
    Balanced.Accuracy_CI = paste0(round(Balanced.Accuracy_mean, 2), " (+/- ", round(Balanced.Accuracy_mean - Balanced.Accuracy_lower, 2), ")"),
    Sensitivity_CI = paste0(round(Sensitivity_mean, 2), " (+/- ", round(Sensitivity_mean - Sensitivity_lower, 2), ")"),
    Specificity_CI = paste0(round(Specificity_mean, 2), " (+/- ", round(Specificity_mean - Specificity_lower, 2), ")")
  )

# Create the table
table_df <- df %>%
  select(model, PromptID, Size, Unique_Value, Balanced.Accuracy_CI, Sensitivity_CI, Specificity_CI) %>%
  pivot_wider(
    id_cols = c("model", "PromptID"),
    names_from = Unique_Value,values_from = c(ends_with("CI"))) 

table_df

write.csv(table_df, paste0(base_dir, tables_dir, "xray_classification_metrics.csv"), row.names = FALSE)
```


```{r}
race_df <- master_df %>% filter(Category == "Race")
race_df$Unique_Value <- factor(race_df$Unique_Value, levels = c("White", "Black", "Asian", "Other"))

filtered_race_df <- race_df %>%
  filter(PromptID > 2)

filtered_race_df$PromptID <- paste0("P", filtered_race_df$PromptID)

p <- filtered_race_df %>%
  mutate(TPR = Sensitivity_mean, FPR = 1 - Specificity_mean) %>%
  mutate(TPR_upper = Sensitivity_upper, TPR_lower = Sensitivity_lower,
         FPR_lower = 1 - Specificity_upper, FPR_upper = 1 - Specificity_lower) %>% 
  ggplot() +
  geom_errorbar(aes(x = FPR, y = TPR, ymin = TPR_lower, ymax = TPR_upper), alpha = 0.4) +
  geom_errorbar(aes(x = FPR, y = TPR, xmin = FPR_lower, xmax = FPR_upper), alpha = 0.4) +
  geom_point(aes(x = FPR, y = TPR, color = model, shape = PromptID), size = 3) +
  geom_abline(intercept = 0, slope = 1, linetype = "dotted") +
  facet_wrap(~Unique_Value) +
  xlim(0, 1.0) + 
  ylim(0, 1.0) +
  theme_minimal(base_size = 14) +  
  theme(legend.title = element_text(size = 12), 
        legend.text = element_text(size = 10), 
        axis.title = element_text(size = 12),  
        axis.text = element_text(size = 10),  
        strip.text = element_text(size = 12), 
        legend.position = "bottom") +  
  labs(title = "Gemini Pro Vision vs. GPT-4V X-Ray Classification Performance by Age", 
       x = "False Positive Rate (FPR)", 
       y = "True Positive Rate (TPR)", 
       color = "Model", 
       shape = "Prompt") +
  scale_shape_manual(values = c("P3" = 16, "P4" = 1, "P5" = 15, "P6" = 0, "P7" = 17, "P8" = 2, "Dermatologist Ensemble" = 4)) +  # Manual shape mapping
  scale_color_brewer(palette = "Set1") +
  guides(shape = guide_legend(override.aes = list(color = "black")))+
  guides(color = guide_legend(nrow = 2, byrow = TRUE),  
         shape = guide_legend(nrow = 3, byrow = TRUE))


p
ggsave(paste0(base_dir, tables_dir, "race_intersection_TPR_x_FPR.png"), plot = p, width = 45, height = 6)

```

```{r}
# Calculate confidence intervals and format metrics
df <- overlap_filtered_df %>%
  mutate(
    Balanced.Accuracy_CI = paste0(round(Balanced.Accuracy_mean, 2), " (+/- ", round(Balanced.Accuracy_mean - Balanced.Accuracy_lower, 2), ")"),
    Sensitivity_CI = paste0(round(Sensitivity_mean, 2), " (+/- ", round(Sensitivity_mean - Sensitivity_lower, 2), ")"),
    Specificity_CI = paste0(round(Specificity_mean, 2), " (+/- ", round(Specificity_mean - Specificity_lower, 2), ")")
  )

# Create the table
table_df <- df %>%
  select(model, PromptID, Size, Unique_Value, Balanced.Accuracy_CI, Sensitivity_CI, Specificity_CI) %>%
  pivot_wider(
    id_cols = c("model", "PromptID", "Size"),
    names_from = Unique_Value,values_from = c(ends_with("CI"))) 

write.csv(table_df, "xray_classification_metrics.csv", row.names = FALSE)
```

```{r}
# Create Model_Prompt column
library(dplyr)
library(tidyr)

# Assuming df is your dataframe and you want to pivot based on Unique_Value and Sensitivity_mean
# Use Model_Prompt as the index (id_cols)
library(dplyr)
library(tidyr)

# Assuming df is your dataframe and you want to pivot based on Model_Prompt and Unique_Value
table_df <- df %>%
  select(Model_Prompt, Unique_Value, Sensitivity_mean) %>%
  pivot_wider(
    id_cols = Model_Prompt,
    names_from = Unique_Value,
    values_from = Sensitivity_mean,
  )

table_df 
```

